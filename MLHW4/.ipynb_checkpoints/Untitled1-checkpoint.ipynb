{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files (x86)\\python\\python37\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "(10, 412)\n",
      "accuracy = 9.74%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "\n",
    "#Be careful with the file path!\n",
    "data = loadmat('data/hw4.mat')\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "y_onehot = encoder.fit_transform(data['y'])\n",
    "    \n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "    \n",
    "def forward_propagate(X, theta1, theta2):\n",
    "    m = X.shape[0] #data number\n",
    "\n",
    "    #theta= matrix of out_size * in_size+1 w*X\n",
    "\n",
    "    #Write codes here\n",
    "    #np.array([np.dot(np.array(w), X[i]) for i in range(m)])\n",
    "    #z = a*w.transpose()\n",
    "    a1 = np.c_[np.ones(m), X] #add an 1 to Xi(first column), type = matrix\n",
    "    z2 = a1 * theta1.transpose() #m*i * i*o = m*o\n",
    "    a2 = np.c_[np.ones(m), sigmoid(z2)] \n",
    "    z3 = a2 * theta2.transpose()\n",
    "    h =  sigmoid(z3)\n",
    "    \n",
    "    return a1, z2, a2, z3, h\n",
    "    \n",
    "def cost(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0]\n",
    "    X = np.matrix(X)\n",
    "    y = np.matrix(y)\n",
    "    # reshape the parameter array into parameter matrices for each layer\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    # run the feed-forward pass\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    # compute the cost\n",
    "    J = 0\n",
    "    for i in range(m):\n",
    "        first_term = np.multiply(-y[i,:], np.log(h[i,:]))\n",
    "        second_term = np.multiply((1 - y[i,:]), np.log(1 - h[i,:]))\n",
    "        J += np.sum(first_term - second_term)\n",
    "        \n",
    "    J = J / m\n",
    "    J += (float(learning_rate) / (2*m) * (np.sum(np.power(theta1[:,1:], 2)) + np.sum(np.power(theta2[:,1:], 2))))\n",
    "    #no need to regularized thetak[:][0] (bias term)\n",
    "    \n",
    "    return J\n",
    "    \n",
    "# initial setup\n",
    "input_size = 400\n",
    "hidden_size = 10\n",
    "num_labels = 10\n",
    "learning_rate = 1\n",
    "lambda_ = 0.01\n",
    "# randomly initialize a parameter array of the size of the full network's parameters\n",
    "params = (np.random.random(size=hidden_size * (input_size + 1) + num_labels * (hidden_size + 1)) - 0.5) * 0.2\n",
    "m = data['X'].shape[0]\n",
    "X = np.matrix(data['X'])\n",
    "y = np.matrix(data['y'])\n",
    "# unravel the parameter array into parameter matrices for each layer\n",
    "theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "\n",
    "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "\n",
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), (1 - sigmoid(z)))    \n",
    "\n",
    "def backprop(params, input_size, hidden_size, num_labels, X, y, learning_rate):\n",
    "    m = X.shape[0] #size\n",
    "   \n",
    "    #Write codes here\n",
    "    #J = 0.0\n",
    "    #grad = grad of each theta(i,j) init= np.zeros(params.shape)\n",
    "\n",
    "    theta1 = np.matrix(np.reshape(params[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "    theta2 = np.matrix(np.reshape(params[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "    a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "    J = cost(params, input_size, hidden_size, num_labels, X, y, learning_rate)\n",
    "\n",
    "    #calculate delta\n",
    "    delta3 = h-y #(m, nlab)\n",
    "    #delta3 = np.multiply(delta3, sigmoid_gradient(z3))\n",
    "    delta2 = np.multiply(delta3*theta2[:,1:], sigmoid_gradient(z2))#(m,n) * (n,hidden+1) (5000*10**10*11)\n",
    "    ###\n",
    "    \n",
    "\n",
    "    d_b2 = (np.sum(delta3, axis=0)/m).transpose() #10*1\n",
    "    d_b1 = (np.sum(delta2, axis=0)/m).transpose() #10*1\n",
    "    #print(a2.shape) 5000*11\n",
    "    d_w2 = np.dot(delta3.transpose(), a2[:,1:])/m + lambda_*theta2[:,1:] #10*10\n",
    "    d_w1 = np.dot(delta2.transpose(), X)/m + lambda_*theta1[:,1:] #10*400\n",
    "    d_t1 = np.array(np.c_[d_b1, d_w1])\n",
    "    d_t2 = np.array(np.c_[d_b2, d_w2])\n",
    "    #print(np.c_[d_t1, d_t2].shape)\n",
    "    grad = np.c_[d_t1, d_t2].flatten()\n",
    "\n",
    "    #for t in range(m):\n",
    "    #\txt = np.matrix(X[t])\n",
    "\n",
    "    return J, grad\n",
    "\n",
    "    \n",
    "from scipy.optimize import minimize\n",
    "# minimize the objective function\n",
    "fmin = minimize(fun=backprop, x0=params, args=(input_size, hidden_size, num_labels, X, y_onehot, learning_rate), method='TNC', jac=True, options={'maxiter': 250})\n",
    "      \n",
    "X = np.matrix(X)\n",
    "theta1 = np.matrix(np.reshape(fmin.x[:hidden_size * (input_size + 1)], (hidden_size, (input_size + 1))))\n",
    "theta2 = np.matrix(np.reshape(fmin.x[hidden_size * (input_size + 1):], (num_labels, (hidden_size + 1))))\n",
    "a1, z2, a2, z3, h = forward_propagate(X, theta1, theta2)\n",
    "y_pred = np.array(np.argmax(h, axis=1) + 1)\n",
    "\n",
    "correct = [1 if a == b else 0 for (a, b) in zip(y_pred, y)]\n",
    "accuracy = (sum(map(int, correct)) / float(len(correct)))\n",
    "print ('accuracy = {0}%'.format(accuracy * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 11)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
